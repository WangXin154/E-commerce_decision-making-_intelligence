===============================================================================
Jupyter Notebook 优化建议报告
===============================================================================

文件：Statistical_analysis_report/01_satisfaction_vs_delivery.ipynb
分析主题：订单满意度与配送延迟关系分析
审查时间：2026-02-18

===============================================================================
一、当前分析总结
===============================================================================

【已完成的工作】✓

1. 数据获取
   - 从MySQL视图 view_order_complete 读取数据
   - 样本量：115,446条订单记录

2. 描述性统计分析
   - 交叉表分析：延迟订单满意度从79%降至25%
   - 满意度下降54个百分点

3. 统计检验
   - 卡方检验：χ² = 11131.46, p < 0.001（高度显著）
   - 证明配送延迟与满意度有极强的关联

4. 单变量逻辑回归
   - Odds Ratio = 0.0895
   - 延迟订单的满意几率仅为非延迟订单的8.9%

5. 多变量逻辑回归
   - 特征：delivered_days, order_value + 特征工程
   - 准确率：81%
   - AUC：0.660

6. 模型对比
   - 逻辑回归 vs 随机森林
   - 逻辑回归表现更好（AUC 0.660 > 0.600）

7. 业务优化
   - 自定义业务成本函数
   - 优化分类阈值至0.35

【分析质量评价】

整体：★★★★☆ (4/5星)
- 分析逻辑清晰，从描述统计到建模完整
- 统计方法运用正确
- 有业务思维（成本优化）

===============================================================================
二、发现的问题（按优先级）
===============================================================================

【严重问题 - 必须修复】

问题1：数据库连接管理错误
位置：Cell 14

问题描述：
- 创建了新的engine但没有dispose
- 之前的engine在Cell 2已经dispose，但后面又创建新的

代码：
```python
sql="""..."""
df= pd.read_sql(sql, engine)  # 这里的engine是哪里来的？
df.head()
```

修复方案：
```python
# 方案1：重新创建并关闭
engine = get_engine()
df = pd.read_sql(sql, engine)
engine.dispose()

# 方案2：使用上下文管理器（推荐）
from contextlib import contextmanager

@contextmanager
def get_db_engine():
    engine = get_engine()
    try:
        yield engine
    finally:
        engine.dispose()

# 使用
with get_db_engine() as engine:
    df = pd.read_sql(sql, engine)
```

---

问题2：未使用的导入和错误的导入
位置：Cell 2

问题描述：
```python
from os import times  # times函数未使用
from joblib import delayed  # delayed未使用
```

修复：删除这两行

---

问题3：变量命名不一致
位置：Cell 12, 13, 18

问题：
- Cell 12: y_prod = model.predict_proba(...)
- Cell 18: y_prob = model_bal.predict_proba(...)

建议：统一使用 y_prob

---

【中等问题 - 强烈建议修复】

问题4：缺少探索性数据分析(EDA)
现状：直接进入建模，缺少对数据的深入理解

缺失的内容：
1. 数据分布可视化
   - delivered_days的分布（直方图）
   - order_value的分布（直方图+箱线图）
   - review_score的分布

2. 相关性分析
   - 特征之间的相关性矩阵热图
   - 检查多重共线性

3. 异常值检测
   - delivered_days的异常值（最大208天）
   - order_value的异常值（最大13664.08）

建议添加的代码：
```python
# 1. 数据概览
print("=== 数据基本信息 ===")
print(df.info())
print("\n=== 描述性统计 ===")
print(df.describe())

# 2. 分布可视化
import matplotlib.pyplot as plt
import seaborn as sns

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# 配送天数分布
axes[0, 0].hist(df['delivered_days'], bins=50, edgecolor='black')
axes[0, 0].set_title('Distribution of Delivery Days')
axes[0, 0].set_xlabel('Days')
axes[0, 0].set_ylabel('Frequency')

# 订单金额分布
axes[0, 1].hist(df['order_value'], bins=50, edgecolor='black')
axes[0, 1].set_title('Distribution of Order Value')
axes[0, 1].set_xlabel('Value (R$)')

# 评分分布
axes[1, 0].bar(df['review_score'].value_counts().sort_index().index,
               df['review_score'].value_counts().sort_index().values)
axes[1, 0].set_title('Distribution of Review Scores')
axes[1, 0].set_xlabel('Score')

# 订单金额箱线图（按是否延迟分组）
df.boxplot(column='order_value', by='is_delayed', ax=axes[1, 1])
axes[1, 1].set_title('Order Value by Delay Status')

plt.tight_layout()
plt.show()

# 3. 相关性分析
correlation = df[['delivered_days', 'order_value', 'review_score', 'is_satisfied']].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)
plt.title('Feature Correlation Matrix')
plt.show()
```

---

问题5：特征工程缺少解释和验证
位置：Cell 16

问题：
- 创建了log_value、delay_squared、value_delay_interaction
- 但没有解释为什么创建这些特征
- 没有验证这些特征是否真的有用

建议添加：
```python
# 1. 特征工程前的假设验证
# 假设1：延迟天数与满意度的关系是否非线性？
plt.figure(figsize=(10, 6))
satisfaction_by_delay = df.groupby('delivered_days')['is_satisfied'].mean()
plt.plot(satisfaction_by_delay.index, satisfaction_by_delay.values)
plt.xlabel('Delivered Days')
plt.ylabel('Satisfaction Rate')
plt.title('Satisfaction Rate vs Delivery Days')
plt.grid(True)
plt.show()
# 如果曲线呈非线性，则需要平方项

# 假设2：订单金额是否与延迟有交互效应？
grouped = df.groupby(['is_delayed', pd.qcut(df['order_value'], q=4)])['is_satisfied'].mean()
grouped.unstack(level=0).plot(kind='bar', figsize=(10, 6))
plt.title('Satisfaction by Order Value Quartiles and Delay Status')
plt.xlabel('Order Value Quartile')
plt.ylabel('Satisfaction Rate')
plt.legend(['Not Delayed', 'Delayed'])
plt.show()

# 2. 特征重要性分析（使用训练好的模型）
feature_importance = pd.DataFrame({
    'feature': features,
    'coefficient': model.coef_[0],
    'abs_coefficient': np.abs(model.coef_[0])
}).sort_values('abs_coefficient', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(feature_importance['feature'], feature_importance['coefficient'])
plt.xlabel('Coefficient')
plt.title('Feature Importance (Logistic Regression Coefficients)')
plt.grid(True)
plt.show()
```

---

问题6：模型评估不够全面
位置：Cell 12, 19

问题：
- 只看了准确率和混淆矩阵
- 缺少Precision、Recall、F1-Score
- 没有分析模型的预测误差

建议添加：
```python
from sklearn.metrics import classification_report, precision_recall_curve

# 1. 完整的分类报告
print("=== Classification Report ===")
print(classification_report(y_test, y_pred,
                          target_names=['Dissatisfied', 'Satisfied']))

# 2. Precision-Recall曲线
precision, recall, thresholds = precision_recall_curve(y_test, y_prob)

plt.figure(figsize=(10, 6))
plt.plot(recall, precision, marker='.')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.grid(True)
plt.show()

# 3. 预测概率分布分析
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(y_prob[y_test == 0], bins=50, alpha=0.5, label='Actual Dissatisfied')
plt.hist(y_prob[y_test == 1], bins=50, alpha=0.5, label='Actual Satisfied')
plt.xlabel('Predicted Probability')
plt.ylabel('Frequency')
plt.title('Distribution of Predicted Probabilities')
plt.legend()

plt.subplot(1, 2, 2)
plt.scatter(y_prob, y_test, alpha=0.1)
plt.xlabel('Predicted Probability')
plt.ylabel('Actual Label')
plt.title('Predicted vs Actual')
plt.grid(True)

plt.tight_layout()
plt.show()
```

---

问题7：随机森林模型表现差但没有深入分析
位置：Cell 29-30

问题：
- 随机森林AUC=0.600，比逻辑回归差
- 只给出了结论，没有分析原因

建议添加分析：
```python
# 1. 随机森林特征重要性
rf_importance = pd.DataFrame({
    'feature': features,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(rf_importance['feature'], rf_importance['importance'])
plt.xlabel('Importance')
plt.title('Random Forest Feature Importance')
plt.show()

print("Feature Importance:")
print(rf_importance)

# 2. 分析为什么随机森林表现差
print("\n=== 分析 ===")
print("可能的原因：")
print("1. 特征数量少（只有5个特征），随机森林的优势无法发挥")
print("2. 特征之间的关系主要是线性的，逻辑回归更适合")
print("3. 样本不平衡（满意:不满意 ≈ 4:1），需要调整class_weight")
print("4. 随机森林容易过拟合小数据集")

# 3. 尝试调优随机森林
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10],
    'class_weight': ['balanced', None]
}

# 注意：这个会很慢，实际项目中使用
# rf_grid = GridSearchCV(RandomForestClassifier(random_state=42),
#                        param_grid, cv=3, scoring='roc_auc')
# rf_grid.fit(x_train, y_train)
# print("Best parameters:", rf_grid.best_params_)
```

---

【轻微问题 - 可选优化】

问题8：代码注释混乱（中英文混杂）

建议：统一使用英文注释，或统一使用中文注释

---

问题9：可视化风格不统一

建议：设置统一的matplotlib样式
```python
import matplotlib.pyplot as plt
import seaborn as sns

# 设置统一的样式
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12
```

---

问题10：缺少交叉验证

当前：只使用了一次train_test_split
建议：使用K-fold交叉验证确保模型稳定性

```python
from sklearn.model_selection import cross_val_score

# 5折交叉验证
cv_scores = cross_val_score(model, x, y, cv=5, scoring='roc_auc')
print(f"Cross-validation AUC scores: {cv_scores}")
print(f"Mean AUC: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})")
```

===============================================================================
三、优化后的完整代码框架
===============================================================================

建议创建一个新的notebook：02_satisfaction_vs_delivery_optimized.ipynb

【结构建议】

## Part 1: 数据加载和初步探索（20%）
1.1 导入库和设置
1.2 加载数据
1.3 数据概览
1.4 数据质量检查

## Part 2: 探索性数据分析（30%）
2.1 单变量分析
2.2 双变量分析
2.3 相关性分析
2.4 异常值检测

## Part 3: 统计检验（10%）
3.1 卡方检验
3.2 单变量逻辑回归
3.3 结果解释

## Part 4: 多变量建模（30%）
4.1 特征工程（带假设验证）
4.2 模型训练
4.3 模型评估（完整指标）
4.4 模型对比
4.5 特征重要性分析

## Part 5: 业务优化（10%）
5.1 业务成本函数
5.2 阈值优化
5.3 业务建议

## Part 6: 总结和下一步（10%）
6.1 关键发现
6.2 业务影响量化
6.3 改进建议
6.4 下一步分析方向

===============================================================================
四、具体优化代码示例
===============================================================================

以下是优化后的关键代码段：

---

【优化1：改进的数据加载（Cell 2替换）】

```python
# 1. 数据加载（使用上下文管理器）
import pandas as pd
import numpy as np
from src.utils.db import get_engine
from contextlib import contextmanager
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# 设置可视化风格
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 11

@contextmanager
def get_db_engine():
    """数据库引擎上下文管理器"""
    engine = get_engine()
    try:
        yield engine
    finally:
        engine.dispose()
        print("Database connection closed.")

# 读取数据
sql = """
SELECT
    is_satisfied,
    is_delayed,
    review_score,
    delivered_days,
    order_value
FROM view_order_complete
WHERE is_delayed IS NOT NULL
  AND review_score IS NOT NULL
"""

with get_db_engine() as engine:
    df = pd.read_sql(sql, engine)

print(f"Data loaded: {len(df):,} rows, {len(df.columns)} columns")
df.head()
```

---

【优化2：完整的EDA部分（新增）】

```python
# =============================================================================
# Part 2: 探索性数据分析 (EDA)
# =============================================================================

print("="*80)
print("EXPLORATORY DATA ANALYSIS")
print("="*80)

# 2.1 数据概览
print("\n--- Data Info ---")
print(df.info())

print("\n--- Descriptive Statistics ---")
print(df.describe())

print("\n--- Missing Values ---")
print(df.isnull().sum())

print("\n--- Class Distribution ---")
print(f"Satisfied orders: {df['is_satisfied'].sum():,} ({df['is_satisfied'].mean()*100:.1f}%)")
print(f"Dissatisfied orders: {(~df['is_satisfied'].astype(bool)).sum():,} ({(1-df['is_satisfied'].mean())*100:.1f}%)")
print(f"Delayed orders: {df['is_delayed'].sum():,} ({df['is_delayed'].mean()*100:.1f}%)")

# 2.2 单变量分析 - 可视化
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
fig.suptitle('Univariate Analysis', fontsize=16, y=1.02)

# Delivered Days
axes[0, 0].hist(df['delivered_days'], bins=50, edgecolor='black', alpha=0.7)
axes[0, 0].axvline(df['delivered_days'].mean(), color='red', linestyle='--',
                   label=f'Mean: {df["delivered_days"].mean():.1f}')
axes[0, 0].set_xlabel('Delivery Days')
axes[0, 0].set_ylabel('Frequency')
axes[0, 0].set_title('Distribution of Delivery Days')
axes[0, 0].legend()
axes[0, 0].grid(alpha=0.3)

# Order Value
axes[0, 1].hist(df['order_value'], bins=50, edgecolor='black', alpha=0.7)
axes[0, 1].axvline(df['order_value'].median(), color='red', linestyle='--',
                   label=f'Median: R${df["order_value"].median():.2f}')
axes[0, 1].set_xlabel('Order Value (R$)')
axes[0, 1].set_ylabel('Frequency')
axes[0, 1].set_title('Distribution of Order Value')
axes[0, 1].legend()
axes[0, 1].grid(alpha=0.3)

# Review Score
review_counts = df['review_score'].value_counts().sort_index()
axes[0, 2].bar(review_counts.index, review_counts.values,
               edgecolor='black', alpha=0.7)
axes[0, 2].set_xlabel('Review Score')
axes[0, 2].set_ylabel('Count')
axes[0, 2].set_title('Distribution of Review Scores')
axes[0, 2].grid(alpha=0.3, axis='y')

# Log Order Value (for better visualization)
axes[1, 0].hist(np.log1p(df['order_value']), bins=50,
                edgecolor='black', alpha=0.7)
axes[1, 0].set_xlabel('Log(Order Value + 1)')
axes[1, 0].set_ylabel('Frequency')
axes[1, 0].set_title('Distribution of Log-transformed Order Value')
axes[1, 0].grid(alpha=0.3)

# Delivery Days by Delay Status
df.boxplot(column='delivered_days', by='is_delayed', ax=axes[1, 1])
axes[1, 1].set_xlabel('Is Delayed')
axes[1, 1].set_ylabel('Delivery Days')
axes[1, 1].set_title('Delivery Days by Delay Status')
axes[1, 1].set_xticklabels(['On Time', 'Delayed'])
plt.sca(axes[1, 1])
plt.xticks([1, 2], ['On Time', 'Delayed'])

# Order Value by Satisfaction
df.boxplot(column='order_value', by='is_satisfied', ax=axes[1, 2])
axes[1, 2].set_xlabel('Is Satisfied')
axes[1, 2].set_ylabel('Order Value (R$)')
axes[1, 2].set_title('Order Value by Satisfaction')
axes[1, 2].set_xticklabels(['Dissatisfied', 'Satisfied'])
plt.sca(axes[1, 2])
plt.xticks([1, 2], ['Dissatisfied', 'Satisfied'])

plt.tight_layout()
plt.show()

# 2.3 双变量分析 - 满意度与延迟的关系
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# 交叉表
ct = pd.crosstab(df['is_delayed'], df['is_satisfied'], normalize='index')
ct.plot(kind='bar', ax=axes[0], color=['#d62728', '#2ca02c'])
axes[0].set_xlabel('Delivery Status')
axes[0].set_ylabel('Proportion')
axes[0].set_title('Satisfaction Rate by Delivery Status')
axes[0].set_xticklabels(['On Time', 'Delayed'], rotation=0)
axes[0].legend(['Dissatisfied', 'Satisfied'])
axes[0].grid(alpha=0.3, axis='y')

# 添加数值标签
for container in axes[0].containers:
    axes[0].bar_label(container, fmt='%.1f%%',
                     labels=[f'{v*100:.1f}%' for v in container.datavalues])

# 配送天数与满意度的关系
satisfaction_by_days = df.groupby('delivered_days')['is_satisfied'].agg(['mean', 'count'])
satisfaction_by_days = satisfaction_by_days[satisfaction_by_days['count'] >= 30]  # 过滤样本量小的

axes[1].plot(satisfaction_by_days.index, satisfaction_by_days['mean']*100,
             marker='o', linewidth=2)
axes[1].set_xlabel('Delivery Days')
axes[1].set_ylabel('Satisfaction Rate (%)')
axes[1].set_title('Satisfaction Rate vs Delivery Days')
axes[1].grid(alpha=0.3)
axes[1].axhline(y=50, color='red', linestyle='--', alpha=0.5, label='50%')
axes[1].legend()

plt.tight_layout()
plt.show()

# 2.4 相关性分析
print("\n--- Correlation Matrix ---")
correlation = df[['delivered_days', 'order_value', 'review_score',
                  'is_satisfied', 'is_delayed']].corr()
print(correlation)

plt.figure(figsize=(10, 8))
sns.heatmap(correlation, annot=True, fmt='.3f', cmap='coolwarm',
            center=0, square=True, linewidths=1)
plt.title('Feature Correlation Matrix', fontsize=14)
plt.tight_layout()
plt.show()

# 2.5 异常值检测
print("\n--- Outlier Detection ---")
Q1 = df['delivered_days'].quantile(0.25)
Q3 = df['delivered_days'].quantile(0.75)
IQR = Q3 - Q1
outlier_threshold = Q3 + 1.5 * IQR

print(f"Delivered Days - IQR: {IQR:.1f}")
print(f"Outlier threshold: {outlier_threshold:.1f} days")
print(f"Number of outliers: {(df['delivered_days'] > outlier_threshold).sum():,} "
      f"({(df['delivered_days'] > outlier_threshold).mean()*100:.1f}%)")

print(f"\nMax delivery days: {df['delivered_days'].max():.0f} days")
print(f"Orders taking >30 days: {(df['delivered_days'] > 30).sum():,} "
      f"({(df['delivered_days'] > 30).mean()*100:.1f}%)")
```

---

【优化3：改进的特征工程（Cell 16替换）】

```python
# =============================================================================
# Part 4.1: 特征工程（Feature Engineering）
# =============================================================================

print("="*80)
print("FEATURE ENGINEERING")
print("="*80)

# 先验假设验证：延迟天数与满意度的关系是否非线性？
print("\n--- Hypothesis Testing: Non-linear Relationship ---")

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# 左图：满意度 vs 配送天数
bins = pd.cut(df['delivered_days'], bins=20)
satisfaction_by_bin = df.groupby(bins)['is_satisfied'].mean()
bin_centers = [(interval.left + interval.right) / 2 for interval in satisfaction_by_bin.index]

axes[0].scatter(bin_centers, satisfaction_by_bin.values, alpha=0.6, s=50)
axes[0].plot(bin_centers, satisfaction_by_bin.values, linewidth=2)
axes[0].set_xlabel('Delivery Days')
axes[0].set_ylabel('Satisfaction Rate')
axes[0].set_title('Satisfaction vs Delivery Days (Binned)')
axes[0].grid(alpha=0.3)

# 右图：订单金额四分位 × 延迟状态
df_temp = df.copy()
df_temp['value_quartile'] = pd.qcut(df_temp['order_value'], q=4,
                                     labels=['Q1', 'Q2', 'Q3', 'Q4'])
grouped = df_temp.groupby(['value_quartile', 'is_delayed'])['is_satisfied'].mean().unstack()

grouped.plot(kind='bar', ax=axes[1], color=['#2ca02c', '#d62728'])
axes[1].set_xlabel('Order Value Quartile')
axes[1].set_ylabel('Satisfaction Rate')
axes[1].set_title('Satisfaction by Value Quartile and Delay Status')
axes[1].legend(['On Time', 'Delayed'])
axes[1].set_xticklabels(grouped.index, rotation=0)
axes[1].grid(alpha=0.3, axis='y')

plt.tight_layout()
plt.show()

print("Observation:")
print("- 左图显示延迟天数与满意度呈非线性关系（需要平方项）")
print("- 右图显示订单金额与延迟有交互效应（需要交互项）")

# 创建特征
print("\n--- Creating Engineered Features ---")

df_model = df.copy()

# 1. Log transformation (减少极值影响)
df_model['log_value'] = np.log1p(df_model['order_value'])

# 2. Polynomial features (捕捉非线性关系)
df_model['delay_squared'] = df_model['delivered_days'] ** 2

# 3. Interaction features (订单金额与延迟的交互)
df_model['value_delay_interaction'] = df_model['order_value'] * df_model['delivered_days']

# 4. 标准化特征（可选，用于解释）
from sklearn.preprocessing import StandardScaler
scaler_original = StandardScaler()
df_model['delivered_days_scaled'] = scaler_original.fit_transform(
    df_model[['delivered_days']]
)

features = [
    'delivered_days',
    'order_value',
    'log_value',
    'delay_squared',
    'value_delay_interaction'
]

print(f"\nOriginal features: 2")
print(f"Engineered features: {len(features)}")
print(f"Feature list: {features}")

# 检查新特征的分布
df_model[features].describe()
```

---

【优化4：完整的模型评估（Cell 18后添加）】

```python
# =============================================================================
# Part 4.3: 完整的模型评估
# =============================================================================

from sklearn.metrics import (classification_report, precision_recall_curve,
                             roc_curve, auc, confusion_matrix)

print("="*80)
print("MODEL EVALUATION")
print("="*80)

# 1. 分类报告
print("\n--- Classification Report ---")
print(classification_report(y_test, y_pred,
                          target_names=['Dissatisfied', 'Satisfied'],
                          digits=3))

# 2. 混淆矩阵（改进的可视化）
cm = confusion_matrix(y_test, y_pred)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# 左图：计数
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],
            xticklabels=['Dissatisfied', 'Satisfied'],
            yticklabels=['Dissatisfied', 'Satisfied'])
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')
axes[0].set_title('Confusion Matrix (Counts)')

# 右图：百分比
cm_pct = cm / cm.sum() * 100
sns.heatmap(cm_pct, annot=True, fmt='.1f', cmap='Blues', ax=axes[1],
            xticklabels=['Dissatisfied', 'Satisfied'],
            yticklabels=['Dissatisfied', 'Satisfied'])
axes[1].set_xlabel('Predicted')
axes[1].set_ylabel('Actual')
axes[1].set_title('Confusion Matrix (Percentages)')

plt.tight_layout()
plt.show()

# 3. Precision-Recall曲线
precision, recall, pr_thresholds = precision_recall_curve(y_test, y_prob)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# PR曲线
axes[0].plot(recall, precision, linewidth=2)
axes[0].set_xlabel('Recall')
axes[0].set_ylabel('Precision')
axes[0].set_title('Precision-Recall Curve')
axes[0].grid(alpha=0.3)

# 最优点
f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
best_idx = np.argmax(f1_scores)
axes[0].scatter(recall[best_idx], precision[best_idx],
               color='red', s=100, zorder=5,
               label=f'Best F1={f1_scores[best_idx]:.3f}')
axes[0].legend()

# 预测概率分布
axes[1].hist(y_prob[y_test == 0], bins=50, alpha=0.5,
            label='Actual Dissatisfied', color='#d62728')
axes[1].hist(y_prob[y_test == 1], bins=50, alpha=0.5,
            label='Actual Satisfied', color='#2ca02c')
axes[1].axvline(best_threshold, color='black', linestyle='--',
               label=f'Optimal Threshold={best_threshold:.3f}')
axes[1].set_xlabel('Predicted Probability')
axes[1].set_ylabel('Frequency')
axes[1].set_title('Distribution of Predicted Probabilities')
axes[1].legend()
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

# 4. 模型性能指标总结
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

print("\n--- Model Performance Metrics ---")
print(f"Accuracy:  {accuracy_score(y_test, y_pred):.3f}")
print(f"Precision: {precision_score(y_test, y_pred):.3f}")
print(f"Recall:    {recall_score(y_test, y_pred):.3f}")
print(f"F1-Score:  {f1_score(y_test, y_pred):.3f}")
print(f"ROC AUC:   {roc_auc:.3f}")

# 5. 错误分析
print("\n--- Error Analysis ---")
errors = pd.DataFrame({
    'actual': y_test.values,
    'predicted': y_pred,
    'probability': y_prob
})
errors['correct'] = errors['actual'] == errors['predicted']

# 假阳性（预测满意，实际不满意）
false_positives = errors[(errors['actual'] == 0) & (errors['predicted'] == 1)]
print(f"False Positives: {len(false_positives):,} ({len(false_positives)/len(errors)*100:.2f}%)")
print(f"  - Average predicted probability: {false_positives['probability'].mean():.3f}")

# 假阴性（预测不满意，实际满意）
false_negatives = errors[(errors['actual'] == 1) & (errors['predicted'] == 0)]
print(f"False Negatives: {len(false_negatives):,} ({len(false_negatives)/len(errors)*100:.2f}%)")
print(f"  - Average predicted probability: {false_negatives['probability'].mean():.3f}")
```

===============================================================================
五、下一步应该做什么
===============================================================================

【短期（本周内）】

优先级1：修复当前notebook的严重问题
□ 修复数据库连接管理（使用上下文管理器）
□ 删除未使用的导入
□ 统一变量命名

优先级2：增强当前分析
□ 添加完整的EDA部分
□ 改进特征工程（加假设验证）
□ 完善模型评估（加precision/recall/F1）

优先级3：创建优化版本
□ 创建 02_satisfaction_vs_delivery_optimized.ipynb
□ 使用本文档提供的优化代码框架
□ 运行并验证结果

【中期（下周）】

新分析1：用户分群分析（RFM模型）
目标：识别不同类型的客户群体

思路：
- 基于Recency、Frequency、Monetary进行用户分层
- 分析各用户群的满意度特征
- 为不同用户群制定针对性策略

文件：02_user_segmentation_rfm.ipynb

---

新分析2：商品类别分析
目标：不同商品类别的满意度和延迟情况

思路：
- 哪些类别最容易延迟？
- 哪些类别的客户对延迟最敏感？
- 高价值商品的满意度如何？

文件：03_product_category_analysis.ipynb

---

新分析3：地理位置分析
目标：各州/城市的配送效率

思路：
- 各州的平均配送时长
- 延迟率地理分布
- 满意度的地理差异

文件：04_geographic_analysis.ipynb

---

新分析4：时间序列分析
目标：满意度和延迟的时间趋势

思路：
- 按月/季度的满意度变化
- 节假日对配送的影响
- 是否有季节性模式？

文件：05_time_series_analysis.ipynb

【长期（机器学习层）】

模型1：客户流失预测模型
目标：预测哪些客户可能流失

特征：
- RFM指标
- 历史满意度
- 延迟次数
- 订单金额趋势

文件：06_churn_prediction_model.ipynb

---

模型2：配送时长预测模型
目标：预测订单的实际配送时长

用途：
- 更准确的配送承诺
- 识别高风险订单
- 优化物流资源分配

文件：07_delivery_time_prediction.ipynb

---

模型3：协同过滤推荐系统
目标：基于用户历史行为推荐商品

文件：08_collaborative_filtering.ipynb

===============================================================================
六、优化检查清单
===============================================================================

在提交最终版本前，请检查：

代码质量：
□ 所有数据库连接都正确关闭
□ 没有未使用的导入
□ 变量命名一致
□ 添加了必要的注释
□ 代码格式统一（使用black或autopep8）

分析完整性：
□ 包含完整的EDA
□ 特征工程有理论支持
□ 模型评估全面（不只是准确率）
□ 包含错误分析
□ 有业务洞察和建议

可视化：
□ 所有图表有标题和标签
□ 使用统一的配色方案
□ 图表清晰易懂
□ 关键发现有高亮

文档：
□ 每个部分有markdown说明
□ 复杂代码有注释
□ 包含关键发现总结
□ 有下一步建议

===============================================================================
七、总结
===============================================================================

你的当前分析已经很不错了！主要优势：
✓ 分析逻辑清晰（描述统计→检验→建模→优化）
✓ 统计方法正确（卡方检验、逻辑回归）
✓ 有业务思维（成本优化）
✓ 结论明确（延迟严重影响满意度）

需要改进的地方：
✗ 缺少深入的EDA
✗ 代码质量有小问题
✗ 模型评估不够全面
✗ 缺少对随机森林表现差的分析

按照本文档的建议优化后，你的分析将达到：
★★★★★ 专业级水平

可以用于：
- 毕业设计
- 求职作品集
- 数据分析报告
- 学术研究

===============================================================================